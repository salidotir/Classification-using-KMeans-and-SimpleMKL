{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cdb1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948ffa8",
   "metadata": {},
   "source": [
    "## Breast-w Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "abb1b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Breast_W_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, output_coloumn_name='Class', \n",
    "                 train_size=0.1, normalization_method='zero_mean_unit_var'):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.output_coloumn_name = output_coloumn_name\n",
    "        self.normalization_method = normalization_method\n",
    "        self.sep = ','\n",
    "        self.coloumn_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "        self.num_of_features = len(self.coloumn_names)-1\n",
    "        self.class_names = ['benign', 'malignant']   # 2 for benign, 4 for malignant\n",
    "        \n",
    "        # read data using pandas\n",
    "        self.dataframe = pd.read_csv(self.dataset_path, sep=self.sep, names=self.coloumn_names)\n",
    "        # replace all '?' with NAN and then remove all NAN rows\n",
    "        self.dataframe = self.dataframe.replace('?', np.nan).dropna(axis = 0, how = 'any')\n",
    "        # rename class-names to +1 & -1 to be used in LibSVM & proposed SimpleMLK method\n",
    "        self.dataframe.replace({self.output_coloumn_name : {2: +1, 4: -1}}, inplace=True)\n",
    "                \n",
    "        self.dataframe = shuffle(self.dataframe)\n",
    "        \n",
    "        data_y = self.dataframe[self.output_coloumn_name].to_numpy().reshape(-1, 1)\n",
    "        data_x = self.dataframe.drop([self.output_coloumn_name], axis=1).to_numpy(dtype='float64')\n",
    "        \n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "        class_1_train_size = (int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        class_minus_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)\n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "#         # split data test & train\n",
    "#         self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "#         self.x_test_size = len(self.dataframe) - self.x_train_size\n",
    "#         self.x_train = self.dataframe.head(self.x_train_size)\n",
    "#         self.x_test = self.dataframe.tail(self.x_test_size)\n",
    "        \n",
    "#         # remove Class from x_ttrain & x_test and create y_train & y_test\n",
    "#         self.y_train = self.x_train[self.output_coloumn_name]\n",
    "#         self.y_test = self.x_test[self.output_coloumn_name]\n",
    "\n",
    "#         # convert to numpy array\n",
    "#         self.y_train = self.y_train.to_numpy().reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.to_numpy().reshape(-1, 1)\n",
    "#         self.x_train = self.x_train.drop([self.output_coloumn_name], axis=1).to_numpy(dtype='float64')\n",
    "#         self.x_test = self.x_test.drop([self.output_coloumn_name], axis=1).to_numpy(dtype='float64')\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.dataframe\n",
    "        \n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e8f37263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Breast-W ...\n",
      "Finished reading dataset  Breast-W ...\n",
      "data shape:  (683, 11)\n",
      "data-train shape:  (68, 10)\n",
      "data-test shape:  (615, 10)\n",
      "output classes:  [-1  1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>385103</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>557583</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1120559</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1223543</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1276091</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "575              385103                5                        1   \n",
       "608              557583                5                       10   \n",
       "68              1120559                8                        3   \n",
       "404             1223543                1                        2   \n",
       "431             1276091                5                        1   \n",
       "\n",
       "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "575                         2                  1                            2   \n",
       "608                        10                 10                           10   \n",
       "68                          8                  3                            4   \n",
       "404                         1                  3                            2   \n",
       "431                         1                  3                            4   \n",
       "\n",
       "    Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "575           1                3                1        1      1  \n",
       "608          10               10                1        1     -1  \n",
       "68            9                8                9        8     -1  \n",
       "404           1                1                2        1      1  \n",
       "431           1                3                2        1      1  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No normalization\n",
    "breast_w_dataset = Breast_W_Dataset('./Datasets/breast-cancer-wisconsin.data', \"Breast-W\", \n",
    "                                    train_size=0.1, 'Class', normalization_method='None')\n",
    "\n",
    "print(\"data shape: \", breast_w_dataset.dataframe.to_numpy().shape)\n",
    "print(\"data-train shape: \", breast_w_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", breast_w_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(breast_w_dataset.y_test))\n",
    "breast_w_dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dfdf91",
   "metadata": {},
   "source": [
    "## Diabetic Retinopathy Debrecen Data Set(Messidor)\n",
    "\n",
    "### * ?**is_class_label_a_feature** -> shows if label is considered as a feature in the dataset or not?\n",
    "\n",
    "### output labels are:\n",
    "    * b'1'\n",
    "    * b'0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2139e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4049dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messidor_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, \n",
    "                 train_size=0.1, normalization_method='zero_mean_unit_var', \n",
    "                 is_class_label_a_feature=False):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.output_coloumn_name = 'Class'\n",
    "        self.normalization_method = normalization_method\n",
    "        self.sep = ','\n",
    "        \n",
    "        # read data using scipy.io.arff\n",
    "        data = arff.loadarff(self.dataset_path)\n",
    "        self.dataframe = pd.DataFrame(data[0])\n",
    "\n",
    "        # remove \"'\" from class names\n",
    "#         self.dataframe.iloc[: , -1] = int(self.dataframe.iloc[: , -1])\n",
    "        self.dataframe['Class'] = self.dataframe['Class'].astype(int)\n",
    "        # replace name of class b'1' to 1 and b'0' to 0\n",
    "        self.dataframe.replace({'Class' : { 1 : +1, 0 : -1}}, inplace=True)\n",
    "        \n",
    "        self.dataframe = shuffle(self.dataframe)\n",
    "                \n",
    "        # split data test & train\n",
    "        self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "        self.x_test_size = len(self.dataframe) - self.x_train_size\n",
    "        self.x_train = self.dataframe.head(self.x_train_size)\n",
    "        self.x_test = self.dataframe.tail(self.x_test_size)\n",
    "        \n",
    "        # remove Class from x_train & x_test and create y_train & y_test\n",
    "        self.y_train = self.x_train[self.output_coloumn_name]\n",
    "        self.y_test = self.x_test[self.output_coloumn_name]\n",
    "\n",
    "        # convert to numpy array\n",
    "        self.y_train = self.y_train.to_numpy().reshape(-1, 1)\n",
    "        self.y_test = self.y_test.to_numpy().reshape(-1, 1)\n",
    "        if is_class_label_a_feature == False:\n",
    "            self.x_train = self.x_train.drop([self.output_coloumn_name], axis=1).to_numpy()\n",
    "            self.x_test = self.x_test.drop([self.output_coloumn_name], axis=1).to_numpy()\n",
    "        elif is_class_label_a_feature == True:\n",
    "            self.x_train = self.x_train.to_numpy()\n",
    "            self.x_test = self.x_test.to_numpy()\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.dataframe\n",
    "\n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "        \n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8c4fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Messidor ...\n",
      "Finished reading dataset  Messidor ...\n",
      "data shape:  (1151, 20)\n",
      "data-train shape:  (115, 19)\n",
      "data-test shape:  (1036, 19)\n",
      "output classes:  [-1  1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>151.059630</td>\n",
       "      <td>79.958925</td>\n",
       "      <td>49.216608</td>\n",
       "      <td>25.911411</td>\n",
       "      <td>16.426327</td>\n",
       "      <td>7.901811</td>\n",
       "      <td>3.525199</td>\n",
       "      <td>1.083237</td>\n",
       "      <td>0.449680</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89.476597</td>\n",
       "      <td>34.502810</td>\n",
       "      <td>18.195406</td>\n",
       "      <td>2.848277</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493727</td>\n",
       "      <td>0.115966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.104340</td>\n",
       "      <td>25.885262</td>\n",
       "      <td>11.161831</td>\n",
       "      <td>2.234820</td>\n",
       "      <td>0.154919</td>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.115039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.458331</td>\n",
       "      <td>15.119368</td>\n",
       "      <td>5.057838</td>\n",
       "      <td>0.194287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502472</td>\n",
       "      <td>0.082811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.818234</td>\n",
       "      <td>3.161544</td>\n",
       "      <td>1.900918</td>\n",
       "      <td>1.524727</td>\n",
       "      <td>1.292870</td>\n",
       "      <td>0.165831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538223</td>\n",
       "      <td>0.098270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5     6     7           8          9  \\\n",
       "977  1.0  1.0  66.0  55.0  45.0  35.0  24.0  11.0  151.059630  79.958925   \n",
       "874  1.0  1.0  17.0  17.0  16.0  15.0  14.0  10.0   89.476597  34.502810   \n",
       "359  1.0  1.0  57.0  54.0  52.0  52.0  48.0  39.0   44.104340  25.885262   \n",
       "389  1.0  1.0  49.0  47.0  46.0  44.0  43.0  37.0   44.458331  15.119368   \n",
       "22   1.0  0.0  37.0  34.0  31.0  30.0  28.0  24.0    8.818234   3.161544   \n",
       "\n",
       "            10         11         12        13        14        15        16  \\\n",
       "977  49.216608  25.911411  16.426327  7.901811  3.525199  1.083237  0.449680   \n",
       "874  18.195406   2.848277   0.024414  0.000000  0.000000  0.000000  0.493727   \n",
       "359  11.161831   2.234820   0.154919  0.024542  0.001534  0.000000  0.516035   \n",
       "389   5.057838   0.194287   0.000000  0.000000  0.000000  0.000000  0.502472   \n",
       "22    1.900918   1.524727   1.292870  0.165831  0.000000  0.000000  0.538223   \n",
       "\n",
       "           17   18  Class  \n",
       "977  0.073810  1.0      1  \n",
       "874  0.115966  0.0     -1  \n",
       "359  0.115039  0.0     -1  \n",
       "389  0.082811  0.0      1  \n",
       "22   0.098270  0.0      1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messidor = Messidor_Dataset('./Datasets/messidor_features.arff', \"Messidor\", \n",
    "                            normalization_method='None', is_class_label_a_feature=False)\n",
    "\n",
    "print(\"data shape: \", messidor.dataframe.to_numpy().shape)\n",
    "print(\"data-train shape: \", messidor.x_train.shape)\n",
    "print(\"data-test shape: \", messidor.x_test.shape)\n",
    "print(\"output classes: \", np.unique(messidor.y_test))\n",
    "messidor.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d567d8",
   "metadata": {},
   "source": [
    "## Car Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f5820e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, output_coloumn_name='Class', \n",
    "                 train_size=0.1):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.output_coloumn_name = output_coloumn_name\n",
    "        self.sep = ','\n",
    "        self.coloumn_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'Class']\n",
    "        self.num_of_features = len(self.coloumn_names)-1\n",
    "        self.class_names = ['benign', 'malignant']   # 2 for benign, 4 for malignant\n",
    "        \n",
    "        # read data using pandas\n",
    "        self.dataframe = pd.read_csv(self.dataset_path, sep=self.sep, names=self.coloumn_names)\n",
    "        # there is no missing attribute in this dataset\n",
    "        \n",
    "        self.dataframe = shuffle(self.dataframe)\n",
    "        \n",
    "        # replace all attribute values to start from 1 and increment by 1\n",
    "        self.dataframe = self.dataframe.replace({'buying'   : { 'vhigh' : 4, 'high' : 3, 'med' : 2, 'low' : 1 }})\n",
    "        self.dataframe = self.dataframe.replace({'maint'    : { 'vhigh' : 4, 'high' : 3, 'med' : 2, 'low' : 1 }})\n",
    "        self.dataframe = self.dataframe.replace({'doors'    : { '2' : 1, '3' : 2, '4' : 3 , '5more' : 4 }})\n",
    "        self.dataframe = self.dataframe.replace({'persons'  : { '2' : 1, '4' : 2, 'more' : 3 }})\n",
    "        self.dataframe = self.dataframe.replace({'lug_boot' : { 'small' : 1, 'med' : 2, 'big' : 3 }})\n",
    "        self.dataframe = self.dataframe.replace({'safety'   : { 'low' : 1, 'med' : 2, 'high' : 3 }})\n",
    "        self.dataframe = self.dataframe.replace({'Class'    : { 'unacc' : 1, 'acc' : 2, 'good' : 3, 'vgood' : 4 }})\n",
    "        \n",
    "        self.data_ = self.dataframe.to_numpy()       \n",
    "        np.random.shuffle(self.data_)\n",
    "\n",
    "        # seperate class labels from data\n",
    "        data_y = self.data_[:, -1]          # for last column\n",
    "        # unacc vs other classes\n",
    "        data_y[data_y==2] = -1\n",
    "        data_y[data_y==3] = -1\n",
    "        data_y[data_y==4] = -1\n",
    "        # data_y[data_y==1] = +1\n",
    "        data_x = self.data_[:, :-1]     # for all but last column\n",
    "        \n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "        class_minus_1_train_size = (int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        class_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)        \n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # split data test & train\n",
    "#         self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "#         self.x_test_size = len(self.dataframe) - self.x_train_size\n",
    "#         self.x_train = self.dataframe.head(self.x_train_size)\n",
    "#         self.x_test = self.dataframe.tail(self.x_test_size)\n",
    "        \n",
    "#         # remove Class from x_ttrain & x_test and create y_train & y_test\n",
    "#         self.y_train = self.x_train[self.output_coloumn_name]\n",
    "#         self.y_test = self.x_test[self.output_coloumn_name]\n",
    "\n",
    "#         # convert to numpy array\n",
    "#         self.y_train = self.y_train.to_numpy().reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.to_numpy().reshape(-1, 1)\n",
    "#         self.x_train = self.x_train.drop([self.output_coloumn_name], axis=1).to_numpy()\n",
    "#         self.x_test = self.x_test.drop([self.output_coloumn_name], axis=1).to_numpy()\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.dataframe\n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8a959492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Car ...\n",
      "Finished reading dataset  Car ...\n",
      "data shape:  (1728, 7)\n",
      "data-train shape:  (172, 6)\n",
      "data-test shape:  (1556, 6)\n",
      "output classes:  [-1  1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety  Class\n",
       "242        2      3      3        3         2       1      1\n",
       "142        1      4      4        3         3       2     -1\n",
       "55         1      4      1        3         3       2     -1\n",
       "1522       3      3      4        2         2       1      1\n",
       "330        1      2      1        1         2       1      1"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No normalization\n",
    "car_dataset = Car_Dataset('./Datasets/car.data', \"Car\", 'Class')\n",
    "\n",
    "print(\"data shape: \", car_dataset.dataframe.to_numpy().shape)\n",
    "print(\"data-train shape: \", car_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", car_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(car_dataset.y_test))\n",
    "car_dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da975783",
   "metadata": {},
   "source": [
    "## Spambase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6ab613c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spambase_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, \n",
    "                 train_size=0.1, normalization_method='zero_mean_unit_var'):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.normalization_method = normalization_method\n",
    "\n",
    "        self.data_ = []\n",
    "        with open(self.dataset_path) as data_file_pointer:\n",
    "            for line in data_file_pointer:\n",
    "                tmp = line.split(\",\")\n",
    "                instance = []\n",
    "                for f in tmp:\n",
    "                    instance.append(float(f))\n",
    "                self.data_.append(instance)\n",
    "                \n",
    "        self.data_ = np.array(self.data_)\n",
    "        np.random.shuffle(self.data_)\n",
    "        \n",
    "        # seperate class labels from data\n",
    "        data_y = self.data_[:, -1]          # for last column\n",
    "        data_y[data_y==0] = -1\n",
    "        data_y[data_y==1] = +1\n",
    "        data_x = self.data_[:, :-1]     # for all but last column\n",
    "\n",
    "        data_y = data_y.reshape(-1, 1)\n",
    "\n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(data_x) * self.train_size)\n",
    "        class_1_train_size = (int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        class_minus_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)\n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # split data test & train\n",
    "#         self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.xdata_, self.y, test_size=1-self.train_size, random_state=42)\n",
    "        \n",
    "#         self.y_train = self.y_train.reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.data_\n",
    "        \n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cd54bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Spambase ...\n",
      "Finished reading dataset  Spambase ...\n",
      "data shape:  (4601, 58)\n",
      "data-train shape:  (459, 57)\n",
      "data-test shape:  (4142, 57)\n",
      "output classes:  [-1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571</td>\n",
       "      <td>11.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.555</td>\n",
       "      <td>42.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.049</td>\n",
       "      <td>48.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.971</td>\n",
       "      <td>34.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2    3     4     5     6     7     8     9   ...     48  \\\n",
       "0  0.00  0.0  0.00  0.0  0.00  0.00  0.00  0.00  0.00  1.05  ...  0.000   \n",
       "1  0.00  0.0  0.00  0.0  0.00  0.00  0.00  0.65  0.00  1.30  ...  0.153   \n",
       "2  0.17  0.0  0.08  0.0  0.42  0.08  0.08  0.42  0.08  0.08  ...  0.000   \n",
       "3  0.00  0.0  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4  0.00  0.0  0.00  0.0  0.00  0.00  0.00  1.57  0.00  1.57  ...  0.000   \n",
       "\n",
       "      49     50     51     52   53     54    55     56   57  \n",
       "0  0.563  0.000  0.000  0.000  0.0  3.571  11.0   75.0 -1.0  \n",
       "1  0.562  0.102  0.000  0.000  0.0  5.555  42.0  500.0 -1.0  \n",
       "2  0.084  0.028  0.098  0.014  0.0  4.049  48.0  575.0  1.0  \n",
       "3  0.000  0.000  0.000  0.000  0.0  1.000   1.0    1.0 -1.0  \n",
       "4  0.372  0.000  0.000  0.000  0.0  3.971  34.0  139.0 -1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase_dataset = Spambase_Dataset('./Datasets/spambase.data', \"Spambase\", \n",
    "                            normalization_method='None')\n",
    "\n",
    "print(\"data shape: \", spambase_dataset.data_.shape)\n",
    "print(\"data-train shape: \", spambase_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", spambase_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(spambase_dataset.y_test))\n",
    "dataframe = pd.DataFrame(spambase_dataset.data_, columns =[i for i in range(58)])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc8751",
   "metadata": {},
   "source": [
    "## Coil2000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d447a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coil2000_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, \n",
    "                 train_size=0.1, normalization_method='zero_mean_unit_var'):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.normalization_method = normalization_method\n",
    "\n",
    "        self.data_ = []\n",
    "        line_number = 0        # skip first 90 lines\n",
    "        with open(self.dataset_path) as data_file_pointer:\n",
    "            for line in data_file_pointer:\n",
    "                if line_number < 90:\n",
    "                    pass\n",
    "                else:\n",
    "                    tmp = line.split(\",\")\n",
    "                    instance = []\n",
    "                    for f in tmp:\n",
    "                        instance.append(float(f))\n",
    "                    self.data_.append(instance)\n",
    "                line_number += 1\n",
    "        \n",
    "        self.data_ = np.array(self.data_)\n",
    "        np.random.shuffle(self.data_)\n",
    "        \n",
    "        # seperate class labels from data\n",
    "        data_y = self.data_[:, -1]          # for last column\n",
    "        data_y[data_y==0] = -1\n",
    "        data_y[data_y==1] = +1\n",
    "        data_x = self.data_[:, :-1]     # for all but last column\n",
    "        \n",
    "        data_y = data_y.reshape(-1, 1)\n",
    "\n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(data_x) * self.train_size)\n",
    "        class_1_train_size = (int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        class_minus_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)\n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # split data test & train\n",
    "#         self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.xdata_, self.y, test_size=1-self.train_size, random_state=42)\n",
    "        \n",
    "#         self.y_train = self.y_train.reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.data_\n",
    "        \n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d5e226e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Coil2000 ...\n",
      "Finished reading dataset  Coil2000 ...\n",
      "data shape:  (9822, 86)\n",
      "data-train shape:  (982, 85)\n",
      "data-test shape:  (8840, 85)\n",
      "output classes:  [-1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...   76   77   78   79  \\\n",
       "0  30.0  1.0  2.0  3.0  7.0  0.0  5.0  1.0  3.0  7.0  ...  0.0  0.0  0.0  1.0   \n",
       "1  33.0  1.0  2.0  3.0  8.0  0.0  7.0  0.0  2.0  7.0  ...  0.0  0.0  0.0  1.0   \n",
       "2   8.0  1.0  3.0  3.0  2.0  1.0  4.0  1.0  4.0  9.0  ...  0.0  0.0  0.0  1.0   \n",
       "3  31.0  1.0  2.0  4.0  7.0  0.0  2.0  0.0  7.0  9.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  12.0  3.0  3.0  2.0  3.0  2.0  1.0  1.0  6.0  6.0  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    80   81   82   83   84   85  \n",
       "0  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coil2000_dataset = Coil2000_Dataset('./Datasets/coil2000.dat', \"Coil2000\", \n",
    "                            normalization_method='None')\n",
    "\n",
    "print(\"data shape: \", coil2000_dataset.data_.shape)\n",
    "print(\"data-train shape: \", coil2000_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", coil2000_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(coil2000_dataset.y_test))\n",
    "dataframe = pd.DataFrame(coil2000_dataset.data_, columns =[i for i in range(86)])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07410088",
   "metadata": {},
   "source": [
    "## Bank Marketing Dataset\n",
    "### * ?**is_class_label_a_feature** -> shows if label is considered as a feature in the dataset or not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4dfd0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bank_Marketing_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, output_coloumn_name='y', \n",
    "                 train_size=0.1, normalization_method='zero_mean_unit_var'):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.output_coloumn_name = output_coloumn_name\n",
    "        self.normalization_method = normalization_method\n",
    "        self.sep = ';'\n",
    "        self.coloumn_names = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"balance\", \"housing\", \"loan\", \"contact\", \"day\", \"month\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"poutcome\", \"y\"]\n",
    "        self.num_of_features = len(self.coloumn_names)-1\n",
    "        self.class_names = ['no', 'yes']\n",
    "        \n",
    "        # read data using pandas\n",
    "        self.dataframe = pd.read_csv(self.dataset_path, sep=self.sep)\n",
    "\n",
    "        \n",
    "#         job_dict = {'management': 0, 'technician': 1, 'entrepreneur': 2, 'blue-collar': 3, 'unknown': 4, 'retired': 5, 'admin.': 6, 'services': 7, 'self-employed': 8, 'unemployed': 9, 'housemaid': 10, 'student': 11}\n",
    "#         edu_dict = {'tertiary': 0, 'secondary': 1, 'unknown': 3, 'primary': 2}\n",
    "#         mar_dict = {'married': 0, 'single': 1, 'divorced': 2}\n",
    "#         default_dict = {'no': 0, 'yes': 1}\n",
    "#         hous_dict = {'yes': 0, 'no': 1}\n",
    "#         loan_dict = default_dict\n",
    "#         contact_dict = {'unknown': 0, 'cellular': 1, 'telephone': 2}\n",
    "#         month_dict = {'may': 0, 'jun': 1, 'jul': 2, 'aug': 3, 'oct': 4, 'nov': 5, 'dec': 6, 'jan': 7, 'feb': 8, 'mar': 9, 'apr': 10, 'sep': 11}\n",
    "#         pout_dict = {'unknown': 0, 'failure': 1, 'other': 3, 'success': 2}\n",
    "\n",
    "#         self.dataframe.replace({'job' : job_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'education' : edu_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'marital' : mar_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'default' : default_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'housing' : hous_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'loan' : loan_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'contact' : contact_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'month' : month_dict}, inplace=True)\n",
    "#         self.dataframe.replace({'poutcome' : pout_dict}, inplace=True)\n",
    "\n",
    "        # convert feature names to numbers\n",
    "        self.nominal_coloumns= ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "        for col_nomi in self.nominal_coloumns:\n",
    "            self.dataframe[col_nomi] = self.dataframe[col_nomi].astype('category').cat.codes\n",
    "\n",
    "        # rename class-names to +1 & -1 to be used in LibSVM & proposed SimpleMLK method\n",
    "        self.dataframe.replace({self.output_coloumn_name : {'yes': +1, 'no': -1}}, inplace=True)\n",
    "                   \n",
    "        \n",
    "        self.dataframe = shuffle(self.dataframe)\n",
    "        \n",
    "        data_y = self.dataframe[self.output_coloumn_name].to_numpy().reshape(-1, 1)\n",
    "        data_x = self.dataframe.drop([self.output_coloumn_name], axis=1).to_numpy(dtype='float64')\n",
    "        \n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "        class_1_train_size = (int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        class_minus_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)\n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        \n",
    "#         # split data test & train\n",
    "#         self.x_train_size = int(len(self.dataframe) * self.train_size)\n",
    "#         self.x_test_size = len(self.dataframe) - self.x_train_size\n",
    "#         self.x_train = self.dataframe.head(self.x_train_size)\n",
    "#         self.x_test = self.dataframe.tail(self.x_test_size)\n",
    "        \n",
    "#         # remove Class from x_ttrain & x_test and create y_train & y_test\n",
    "#         self.y_train = self.x_train[self.output_coloumn_name]\n",
    "#         self.y_test = self.x_test[self.output_coloumn_name]\n",
    "        \n",
    "#         # convert to numpy array\n",
    "#         self.y_train = self.y_train.to_numpy().reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.to_numpy().reshape(-1, 1)\n",
    "#         self.x_train = self.x_train.drop([self.output_coloumn_name], axis=1).to_numpy(dtype='float64')\n",
    "#         self.x_test = self.x_test.drop([self.output_coloumn_name], axis=1).to_numpy(dtype='float64')\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.dataframe\n",
    "        \n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "        \n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b85ee9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Bank Marketing ...\n",
      "Finished reading dataset  Bank Marketing ...\n",
      "data shape:  (45211, 17)\n",
      "data-train shape:  (4521, 16)\n",
      "data-test shape:  (40690, 16)\n",
      "output classes:  [-1  1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13121</th>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-834</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10162</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>473</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12564</th>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>676</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35715</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1794</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "13121   53    9        0          0        0     -834        1     1        0   \n",
       "20685   44    4        1          1        0      781        1     0        0   \n",
       "10162   40   10        0          1        0        0        0     0        2   \n",
       "12564   33    7        1          1        0      114        0     1        2   \n",
       "35715   48    1        1          1        0     1794        1     1        0   \n",
       "\n",
       "       day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "13121    8      5       130         1     -1         0         3 -1  \n",
       "20685   12      1       112         5     -1         0         3 -1  \n",
       "10162   11      6       473         1     -1         0         3 -1  \n",
       "12564    3      5       676         1     -1         0         3  1  \n",
       "35715    8      8        97         1    343         2         0 -1  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No normalization\n",
    "bank_dataset = Bank_Marketing_Dataset('./Datasets/bank-full.csv', \"Bank Marketing\", 'y', normalization_method=\"None\")\n",
    "\n",
    "print(\"data shape: \", bank_dataset.dataframe.to_numpy().shape)\n",
    "print(\"data-train shape: \", bank_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", bank_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(bank_dataset.y_test))\n",
    "bank_dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6d402",
   "metadata": {},
   "source": [
    "## Skin Segmentation Dataset\n",
    "### * ?**is_class_label_a_feature** -> shows if label is considered as a feature in the dataset or not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "292e9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skin_NonSkin_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, train_size=0.1, normalization_method='zero_mean_unit_var'):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.normalization_method = normalization_method\n",
    "\n",
    "        self.data_ = []\n",
    "        with open(self.dataset_path) as data_file_pointer:\n",
    "            for line in data_file_pointer:\n",
    "                tmp = line.split()\n",
    "                instance = []\n",
    "                for f in tmp:\n",
    "                    instance.append(float(f))\n",
    "                self.data_.append(instance)\n",
    "        \n",
    "        self.data_ = np.array(self.data_)\n",
    "        np.random.shuffle(self.data_)\n",
    "        \n",
    "        # seperate class labels from data\n",
    "        data_y = self.data_[:, -1]          # for last column\n",
    "        data_y[data_y==2] = -1\n",
    "        data_y[data_y==1] = +1\n",
    "        data_x = self.data_[:, :-1]     # for all but last column\n",
    "        \n",
    "        data_y = data_y.reshape(-1, 1)\n",
    "\n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(data_x) * self.train_size)\n",
    "        class_1_train_size = (int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        class_minus_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)\n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # split data test & train\n",
    "#         self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.xdata_, self.y, test_size=1-self.train_size, random_state=42)\n",
    "        \n",
    "#         self.y_train = self.y_train.reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.data_\n",
    "        \n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5227820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Skin Segmentation ...\n",
      "Finished reading dataset  Skin Segmentation ...\n",
      "data shape:  (245057, 4)\n",
      "data-train shape:  (24505, 3)\n",
      "data-test shape:  (220552, 3)\n",
      "output classes:  [-1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2    3\n",
       "0  135.0  173.0  221.0  1.0\n",
       "1  169.0  182.0  234.0  1.0\n",
       "2  177.0  174.0  130.0 -1.0\n",
       "3  121.0   69.0   52.0 -1.0\n",
       "4  205.0  203.0  169.0 -1.0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_dataset = Skin_NonSkin_Dataset('./Datasets/Skin_NonSkin.txt', \"Skin Segmentation\", normalization_method=\"None\")\n",
    "\n",
    "print(\"data shape: \", skin_dataset.data_.shape)\n",
    "print(\"data-train shape: \", skin_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", skin_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(skin_dataset.y_test))\n",
    "dataframe = pd.DataFrame(skin_dataset.data_, columns =[i for i in range(4)])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e1a93",
   "metadata": {},
   "source": [
    "## Covertype Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ccfe1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Covertype_Dataset:\n",
    "    def __init__(self, dataset_path, dataset_name, output_coloumn_name='44', \n",
    "                 train_size=0.1, normalization_method='zero_mean_unit_var'):\n",
    "        \"\"\"\n",
    "        self.x_train\n",
    "        self.x_test\n",
    "        self.y_train\n",
    "        self.y_test\n",
    "        \"\"\"\n",
    "        print(\"Started reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_size = train_size\n",
    "        self.normalization_method = normalization_method\n",
    "\n",
    "        self.data_ = []\n",
    "        with open(self.dataset_path) as data_file_pointer:\n",
    "            for line in data_file_pointer:\n",
    "                tmp = line.split(\",\")\n",
    "                instance = []\n",
    "                for f in tmp:\n",
    "                    instance.append(float(f))\n",
    "                self.data_.append(instance)\n",
    "        \n",
    "        self.data_ = np.array(self.data_)       \n",
    "        np.random.shuffle(self.data_)\n",
    "\n",
    "        # seperate class labels from data\n",
    "        data_y = self.data_[:, -1]          # for last column\n",
    "        # in the article, it is said to only consider Aspen vs other classes\n",
    "        # due to dataset description, Aspen class is the class label '5'.\n",
    "        data_y[data_y==1] = -1\n",
    "        data_y[data_y==2] = -1\n",
    "        data_y[data_y==3] = -1\n",
    "        data_y[data_y==4] = -1\n",
    "        data_y[data_y==6] = -1\n",
    "        data_y[data_y==7] = -1\n",
    "        data_y[data_y==5] = +1\n",
    "        data_x = self.data_[:, :-1]     # for all but last column\n",
    "        \n",
    "        data_y = data_y.reshape(-1, 1)\n",
    "\n",
    "        # since all class labesl are either +1 or -1\n",
    "        class_1_data_x = data_x[np.where(data_y==1)[0]]\n",
    "        class_1_data_y = data_y[data_y==1]\n",
    "        class_minus_1_data_x = data_x[np.where(data_y==-1)[0]]\n",
    "        class_minus_1_data_y = data_y[data_y==-1]\n",
    "        \n",
    "        # to create a balanced dataset, get random datas from each class equaly\n",
    "        self.x_train_size = int(len(data_x) * self.train_size)\n",
    "        class_1_train_size = (int(self.x_train_size/2))/len(class_1_data_x)\n",
    "        class_minus_1_train_size = (self.x_train_size - int(self.x_train_size/2))/len(class_minus_1_data_x)\n",
    "        \n",
    "        class_1_x_train, class_1_x_test, class_1_y_train, class_1_y_test = \\\n",
    "                        train_test_split(class_1_data_x, class_1_data_y, \n",
    "                                         train_size=class_1_train_size, random_state=42)\n",
    "        class_minus_1_x_train, class_minus_1_x_test, class_minus_1_y_train, class_minus_1_y_test = \\\n",
    "                        train_test_split(class_minus_1_data_x, class_minus_1_data_y, \n",
    "                                         train_size=class_minus_1_train_size, random_state=42)\n",
    "        \n",
    "        self.x_train = np.concatenate((class_1_x_train, class_minus_1_x_train), axis=0)\n",
    "        self.x_test = np.concatenate((class_1_x_test, class_minus_1_x_test), axis=0)\n",
    "        self.y_train = np.concatenate((class_1_y_train, class_minus_1_y_train), axis=0)\n",
    "        self.y_test = np.concatenate((class_1_y_test, class_minus_1_y_test), axis=0)\n",
    "        \n",
    "        self.y_train = self.y_train.reshape(-1, 1)\n",
    "        self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "#         # split data test & train\n",
    "#         self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.xdata_, self.y, test_size=1-self.train_size, random_state=42)\n",
    "        \n",
    "#         self.y_train = self.y_train.reshape(-1, 1)\n",
    "#         self.y_test = self.y_test.reshape(-1, 1)\n",
    "        \n",
    "        # remove self.dataframe to avoid storing data too much\n",
    "#         del self.data_\n",
    "        \n",
    "        # Normalize data\n",
    "        self.normalize(self.normalization_method)\n",
    "\n",
    "        print(\"Finished reading dataset \", dataset_name, \"...\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    Normalizing data improves the convergence of learning model and causes that smaller features also be able to affect the model parameters.\n",
    "    \"\"\"\n",
    "    def normalize(self, normalization_method):\n",
    "        if normalization_method == 'none':\n",
    "            print(\"No normalization.\")\n",
    "            return\n",
    "        \n",
    "        if normalization_method == 'zero_mean_unit_var':\n",
    "            print(\"zero-mean & unit_variance normalization.\")\n",
    "            self.x_train_without_x0 = self.zero_mean_unit_variance(self.x_train)\n",
    "            self.x_test_without_x0 = self.zero_mean_unit_variance(self.x_test)\n",
    "            \n",
    "            \n",
    "        if normalization_method == 'scale_0_1':\n",
    "            print(\"scaling to [0, 1] normalization.\")\n",
    "            self.x_train_without_x0 = self.scaling_between_0_1(self.x_train)\n",
    "            self.x_test_without_x0 = self.scaling_between_0_1(self.x_test)\n",
    "     \n",
    "    \n",
    "    def scaling_between_0_1(self, numpy_array):\n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.min(axis=0)) / (numpy_array.max(axis=0) - numpy_array.min(axis=0))\n",
    "        return normed_numpy_array\n",
    "\n",
    "\n",
    "    def zero_mean_unit_variance(self, numpy_array):\n",
    "        '''\n",
    "        Standardization\n",
    "        '''\n",
    "        normed_numpy_array = (numpy_array - numpy_array.mean(axis=0)) / numpy_array.std(axis=0)\n",
    "        return normed_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "830a9514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset  Covertype ...\n",
      "Finished reading dataset  Covertype ...\n",
      "data shape:  (581012, 55)\n",
      "data-train shape:  (11620, 54)\n",
      "data-test shape:  (569392, 54)\n",
      "output classes:  [-1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3238.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4595.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2791.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2984.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3208.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2998.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3266.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3113.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2      3      4       5      6      7      8       9   \\\n",
       "0  3238.0  246.0   3.0  474.0   59.0  4595.0  213.0  241.0  166.0  2791.0   \n",
       "1  2984.0  260.0  26.0  350.0  171.0  1530.0  149.0  243.0  227.0   365.0   \n",
       "2  3208.0   85.0  10.0  454.0   33.0  4010.0  235.0  223.0  119.0  2998.0   \n",
       "3  3266.0  348.0  12.0  256.0   78.0  1509.0  197.0  220.0  161.0  2892.0   \n",
       "4  3113.0  285.0  13.0  228.0   71.0   589.0  182.0  239.0  197.0  1376.0   \n",
       "\n",
       "   ...   45   46   47   48   49   50   51   52   53   54  \n",
       "0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "1  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "2  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 -1.0  \n",
       "4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covertype_dataset = Covertype_Dataset('./Datasets/covtype.data', \"Covertype\", \n",
    "                                      train_size=0.02, normalization_method=\"None\")\n",
    "\n",
    "print(\"data shape: \", covertype_dataset.data_.shape)\n",
    "print(\"data-train shape: \", covertype_dataset.x_train.shape)\n",
    "print(\"data-test shape: \", covertype_dataset.x_test.shape)\n",
    "print(\"output classes: \", np.unique(covertype_dataset.y_test))\n",
    "dataframe = pd.DataFrame(covertype_dataset.data_, columns =[i for i in range(55)])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dec184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
